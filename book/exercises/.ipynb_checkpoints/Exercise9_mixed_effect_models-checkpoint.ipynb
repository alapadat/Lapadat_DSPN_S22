{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2W919d2ZXp7"
   },
   "source": [
    "# Exercise 9: Mixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4nOzVhyZXqK"
   },
   "source": [
    "This homework assignment is designed to give you practice fitting and interpreting mixed effects models. \n",
    "\n",
    "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again. \n",
    "\n",
    "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file. \n",
    "\n",
    "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DsyBTB6ZXqN"
   },
   "source": [
    "---\n",
    "## 1. Loading and formatting the data (1 point)\n",
    "\n",
    "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**. \n",
    "\n",
    "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UnBVazYfZXqP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.1     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.4     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 1.0.0\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n"
     ]
    }
   ],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "setwd(\"C:/Users/roman/OneDrive/Documents/Python Scripts/DataSciencePsychNeuro-master/Homework datasets/LexDat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>157</td><td>1</td><td>1</td><td>710  </td><td>browse     </td><td>false</td><td>-0.437</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 67</td><td>1</td><td>1</td><td>1,094</td><td>refrigerant</td><td>false</td><td> 0.825</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>120</td><td>1</td><td>1</td><td>587  </td><td>gaining    </td><td>false</td><td>-0.645</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 21</td><td>1</td><td>1</td><td>984  </td><td>cheerless  </td><td>false</td><td> 0.025</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>236</td><td>1</td><td>1</td><td>577  </td><td>pattered   </td><td>false</td><td>-0.763</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>236</td><td>2</td><td>1</td><td>715  </td><td>conjures   </td><td>false</td><td>-0.364</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore\\\\\n",
       "  & <int> & <int> & <int> & <chr> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 157 & 1 & 1 & 710   & browse      & false & -0.437\\\\\n",
       "\t2 &  67 & 1 & 1 & 1,094 & refrigerant & false &  0.825\\\\\n",
       "\t3 & 120 & 1 & 1 & 587   & gaining     & false & -0.645\\\\\n",
       "\t4 &  21 & 1 & 1 & 984   & cheerless   & false &  0.025\\\\\n",
       "\t5 & 236 & 1 & 1 & 577   & pattered    & false & -0.763\\\\\n",
       "\t6 & 236 & 2 & 1 & 715   & conjures    & false & -0.364\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;chr&gt; | D_Word &lt;chr&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | 157 | 1 | 1 | 710   | browse      | false | -0.437 |\n",
       "| 2 |  67 | 1 | 1 | 1,094 | refrigerant | false |  0.825 |\n",
       "| 3 | 120 | 1 | 1 | 587   | gaining     | false | -0.645 |\n",
       "| 4 |  21 | 1 | 1 | 984   | cheerless   | false |  0.025 |\n",
       "| 5 | 236 | 1 | 1 | 577   | pattered    | false | -0.763 |\n",
       "| 6 | 236 | 2 | 1 | 715   | conjures    | false | -0.364 |\n",
       "\n"
      ],
      "text/plain": [
       "  Sub_ID Trial Type D_RT  D_Word      Outlier D_Zscore\n",
       "1 157    1     1    710   browse      false   -0.437  \n",
       "2  67    1     1    1,094 refrigerant false    0.825  \n",
       "3 120    1     1    587   gaining     false   -0.645  \n",
       "4  21    1     1    984   cheerless   false    0.025  \n",
       "5 236    1     1    577   pattered    false   -0.763  \n",
       "6 236    2     1    715   conjures    false   -0.364  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Occurrences</th><th scope=col>Word</th><th scope=col>Length</th><th scope=col>Freq_HAL</th><th scope=col>Log_Freq_HAL</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>synergistic</td><td>11</td><td>284  </td><td>5.649</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>synonymous </td><td>10</td><td>951  </td><td>6.858</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>syntactical</td><td>11</td><td>114  </td><td>4.736</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>synthesis  </td><td> 9</td><td>6,742</td><td>8.816</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1</td><td>synthesized</td><td>11</td><td>2,709</td><td>7.904</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1</td><td>synthesizer</td><td>11</td><td>1,390</td><td>7.237</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Occurrences & Word & Length & Freq\\_HAL & Log\\_Freq\\_HAL\\\\\n",
       "  & <int> & <chr> & <int> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & synergistic & 11 & 284   & 5.649\\\\\n",
       "\t2 & 1 & synonymous  & 10 & 951   & 6.858\\\\\n",
       "\t3 & 1 & syntactical & 11 & 114   & 4.736\\\\\n",
       "\t4 & 1 & synthesis   &  9 & 6,742 & 8.816\\\\\n",
       "\t5 & 1 & synthesized & 11 & 2,709 & 7.904\\\\\n",
       "\t6 & 1 & synthesizer & 11 & 1,390 & 7.237\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | Occurrences &lt;int&gt; | Word &lt;chr&gt; | Length &lt;int&gt; | Freq_HAL &lt;chr&gt; | Log_Freq_HAL &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 1 | synergistic | 11 | 284   | 5.649 |\n",
       "| 2 | 1 | synonymous  | 10 | 951   | 6.858 |\n",
       "| 3 | 1 | syntactical | 11 | 114   | 4.736 |\n",
       "| 4 | 1 | synthesis   |  9 | 6,742 | 8.816 |\n",
       "| 5 | 1 | synthesized | 11 | 2,709 | 7.904 |\n",
       "| 6 | 1 | synthesizer | 11 | 1,390 | 7.237 |\n",
       "\n"
      ],
      "text/plain": [
       "  Occurrences Word        Length Freq_HAL Log_Freq_HAL\n",
       "1 1           synergistic 11     284      5.649       \n",
       "2 1           synonymous  10     951      6.858       \n",
       "3 1           syntactical 11     114      4.736       \n",
       "4 1           synthesis    9     6,742    8.816       \n",
       "5 1           synthesized 11     2,709    7.904       \n",
       "6 1           synthesizer 11     1,390    7.237       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LexicalData <- read.csv(\"LexicalData.csv\")\n",
    "head(LexicalData)\n",
    "\n",
    "Items <- read.csv(\"Items.csv\")\n",
    "head(Items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting\n",
    "\n",
    "Remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "\u001b[1m\u001b[33mError\u001b[39m in `left_join()`:\u001b[22m\n\u001b[1m\u001b[22m\u001b[33m!\u001b[39m Join columns in `y` must be present in the data.\n\u001b[31m✖\u001b[39m Problem with `Sub_ID`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[33mError\u001b[39m in `left_join()`:\u001b[22m\n\u001b[1m\u001b[22m\u001b[33m!\u001b[39m Join columns in `y` must be present in the data.\n\u001b[31m✖\u001b[39m Problem with `Sub_ID`.\nTraceback:\n",
      "1. left_join(LexicalData, Items, by = \"Sub_ID\") %>% left_join()",
      "2. left_join(.)",
      "3. left_join(LexicalData, Items, by = \"Sub_ID\")",
      "4. left_join.data.frame(LexicalData, Items, by = \"Sub_ID\")",
      "5. join_mutate(x = x, y = y, by = by, type = \"left\", suffix = suffix, \n .     na_matches = na_matches, keep = keep, multiple = multiple, \n .     unmatched = unmatched, user_env = caller_env())",
      "6. join_cols(x_names = x_names, y_names = y_names, by = by, suffix = suffix, \n .     keep = keep, error_call = error_call)",
      "7. check_join_vars(by$y, y_names, by$condition, \"y\", error_call = error_call)",
      "8. abort(bullets, call = error_call)",
      "9. signal_abort(cnd, .file)"
     ]
    }
   ],
   "source": [
    "LexicalData  <- LexicalData %>%\n",
    "  mutate(D_RT = as.numeric(gsub(\",\",\"\",D_RT)))\n",
    "\n",
    "\n",
    "left_join(LexicalData, Items, by = \"Sub_ID\") %>%\n",
    "\n",
    "#  Syntax (*_join): \n",
    "#\n",
    "#  *_join(x, y, by = \"ID\")\n",
    "\n",
    "left_join()\n",
    "\n",
    "head(LexicalData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXy81Viishk1"
   },
   "source": [
    "---\n",
    "## 2. Model fitting (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7_gEgkbzFtU"
   },
   "source": [
    "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIOIg-GRz4rN"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbeg_JrS3mwU"
   },
   "source": [
    "Now, install `lme4` using `install.packages()` and then load the library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFSnvvb_re2O"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZJns7xr41nW"
   },
   "source": [
    "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kjwT0je57N7"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfb_ovk7JFGt"
   },
   "source": [
    "---\n",
    "## 3. Model assessment (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7B1Ux6RHGjy"
   },
   "source": [
    "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCi5gYOeHo6m"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hukKG1AbGqXM"
   },
   "source": [
    "Use the Aikeke Information Criterion (AIC) to compare these two models. Which one is better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMDg8qb5FhJz"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4oTfsYmIvYt"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARF2PF2yLXkZ"
   },
   "source": [
    "---\n",
    "##  4. Reflection (1 point)\n",
    "\n",
    "What other random effects could be controlled for in this data set? \n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4MPECMmZXqe"
   },
   "source": [
    "**DUE:** 5pm EST, March 15, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9GUofXN4BVy"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> *Someone's Name*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
