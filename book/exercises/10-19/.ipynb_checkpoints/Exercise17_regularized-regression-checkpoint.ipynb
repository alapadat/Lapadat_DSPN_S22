{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0-Q9NYTBujb"
   },
   "source": [
    "# Exercise 17: Regularized regression\n",
    "\n",
    "This homework assignment is designed to give you an intuition as an interesting property of regularization in the context of ultra-high dimensional statistical problems.\n",
    "\n",
    "You won't need to load in any data for this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODln6rvBujd"
   },
   "source": [
    "---\n",
    "## 1. Simulating & visualizing data (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sezRLzgHBuje"
   },
   "source": [
    "We are going to be looking at what happens in the context where $p>n$. In order to have total control over our data, we will use simulations for this homework. First, we will need to load the `glmnet`, `tidyverse`, and `ggplot2` libraries for this assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LVJwea2rBujf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'glmnet' is in use and will not be installed\"\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"glmnet\")\n",
    "library(glmnet)\n",
    "library(tidyverse)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXwMchX7Bujf"
   },
   "source": [
    "We are going to generate a data set with complex structure and try to recover it using polynomial models. For simplicity sake, use the following code to produce a response variable, $y$ that has complex structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpLho0wUde1L"
   },
   "source": [
    "*Hint: Look up what a cosine function looks like if you need a reminder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BeK03Sx7Bujg"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "set.seed(121)\n",
    "sigma_noise = .5\n",
    "x=seq(-9,9,by=.18)\n",
    "n=length(x)\n",
    "y = 0.1*x + cos(x) + cos(x/20)+rnorm(n,sd=sigma_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfmUWGIlBujg"
   },
   "source": [
    "(a) Break the data into a training set (n=50) and test set (n=51) using the `sample` function to randomly select subsets of x and y.  Make a separate data frame for the training and test data.\n",
    "\n",
    "(**Note**: *Do not* just take the first 50 observations to be the training set and last 51 observations to be the test set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rIg6XGaHBujg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>x</th><th scope=col>y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 1.62</td><td>1.7430629</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-1.80</td><td>1.5154726</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 8.28</td><td>2.0148737</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 5.94</td><td>0.2112119</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 7.74</td><td>0.2369539</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-7.02</td><td>1.5256458</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & x & y\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  1.62 & 1.7430629\\\\\n",
       "\t2 & -1.80 & 1.5154726\\\\\n",
       "\t3 &  8.28 & 2.0148737\\\\\n",
       "\t4 &  5.94 & 0.2112119\\\\\n",
       "\t5 &  7.74 & 0.2369539\\\\\n",
       "\t6 & -7.02 & 1.5256458\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | x &lt;dbl&gt; | y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 |  1.62 | 1.7430629 |\n",
       "| 2 | -1.80 | 1.5154726 |\n",
       "| 3 |  8.28 | 2.0148737 |\n",
       "| 4 |  5.94 | 0.2112119 |\n",
       "| 5 |  7.74 | 0.2369539 |\n",
       "| 6 | -7.02 | 1.5256458 |\n",
       "\n"
      ],
      "text/plain": [
       "  x     y        \n",
       "1  1.62 1.7430629\n",
       "2 -1.80 1.5154726\n",
       "3  8.28 2.0148737\n",
       "4  5.94 0.2112119\n",
       "5  7.74 0.2369539\n",
       "6 -7.02 1.5256458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>x</th><th scope=col>y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-0.18</td><td>0.2132742</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 8.10</td><td>2.4078645</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 3.96</td><td>1.8210194</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-8.82</td><td>1.1226488</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 1.44</td><td>0.4207930</td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 6.66</td><td>0.6696763</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & x & y\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & -0.18 & 0.2132742\\\\\n",
       "\t2 &  8.10 & 2.4078645\\\\\n",
       "\t3 &  3.96 & 1.8210194\\\\\n",
       "\t4 & -8.82 & 1.1226488\\\\\n",
       "\t5 &  1.44 & 0.4207930\\\\\n",
       "\t6 &  6.66 & 0.6696763\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | x &lt;dbl&gt; | y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 | -0.18 | 0.2132742 |\n",
       "| 2 |  8.10 | 2.4078645 |\n",
       "| 3 |  3.96 | 1.8210194 |\n",
       "| 4 | -8.82 | 1.1226488 |\n",
       "| 5 |  1.44 | 0.4207930 |\n",
       "| 6 |  6.66 | 0.6696763 |\n",
       "\n"
      ],
      "text/plain": [
       "  x     y        \n",
       "1 -0.18 0.2132742\n",
       "2  8.10 2.4078645\n",
       "3  3.96 1.8210194\n",
       "4 -8.82 1.1226488\n",
       "5  1.44 0.4207930\n",
       "6  6.66 0.6696763"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "#length(y)\n",
    "#typeof(y)\n",
    "\n",
    "trainy = sample(y, size = 50, replace = FALSE)\n",
    "trainx = sample(x, size = 50, replace = FALSE)\n",
    "train = data.frame(x = trainx, y = trainy) # defines train\n",
    "\n",
    "head(train)\n",
    "\n",
    "testy = sample(y, size = 51, replace = FALSE)\n",
    "testx = sample(x, size = 51, replace = FALSE)\n",
    "test = data.frame(x = testx, y = testy)\n",
    "\n",
    "head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ4B7a1lBujg"
   },
   "source": [
    "(b) Plot the training data ($x$ \\& $y$). Describe the relationship that you see in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "hRyRddZJBujh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaVD7SEeBuji"
   },
   "source": [
    "How would you describe the relationship between $x$ and $y$ based on this plot?\n",
    "\n",
    "> *Weakly correlated, appears to be positive.*\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqLPa45zBuji"
   },
   "source": [
    "---\n",
    "## 2. Bias-variance tradeoff: polynomial regression (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyP55tOade1P"
   },
   "source": [
    "Recall that in polynomial regression we increase model complexity by expanding $x$ out to the power $k$ (which we call degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxra2iFvde1Q"
   },
   "source": [
    "\n",
    "$$Y = \\hat{\\beta}_0 + \\sum_{j=1}^K \\hat{\\beta}_jX^j $$  \n",
    "\n",
    "$$ = poly(x,k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SvSDGa9Buji"
   },
   "source": [
    "(a) Fit a 2nd degree polynomial regression model to the training data. Plot the results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vysWxHwVde1R"
   },
   "source": [
    "*Hint: Use the* `help` *function to see how to use the* `stat_smooth()` *and* `poly()` *functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "R_mZIsWwBuji"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = train$x ~ poly(y, 4), data = train)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)  poly(y, 4)1  poly(y, 4)2  poly(y, 4)3  poly(y, 4)4  \n",
       "     0.9432      -2.6523       8.7537       0.2962      -9.3764  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "lm.fit = lm(train$x~poly(y,4), data=train)\n",
    "lm.fit\n",
    "\n",
    "ggplot(train(aes(x,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYxz29TyBujj"
   },
   "source": [
    "How well does this 2nd degree polynomial model qualitatively fit the data? Could it do better? \n",
    "\n",
    "> *Write your response here*\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A83iJUkBujj"
   },
   "source": [
    "(b) Fit a 12th degree polynomial to the data. Does this do qualitatively better or worse than the 2nd degree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZAQ0PB5Bujj"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xanWSXvBujk"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpDFP-eSBujl"
   },
   "source": [
    "(c) Modify the loop below to estimate the bias-variance tradeoff as model complexity (i.e., degree of the polynomial model, $k$) increases from 2 to 50. Use the training data to fit the model and test data to evaluate its predictive accuracy. \n",
    "\n",
    "Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2kXJb-5de1S"
   },
   "source": [
    "\n",
    "(**Note**: We are using median accuracies here because there are often 1 or 2 outlier values in the higher degree polynomial models that can throw off the accuracy estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnoZVv4OBujl"
   },
   "outputs": [],
   "source": [
    "# Now do the variance-bias trade off analysis using regular regression\n",
    "degree = seq(2,50)\n",
    "\n",
    "# Need to setup your output vectors\n",
    "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "\n",
    "for (k in degree) {\n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "}\n",
    "\n",
    "# Plot your results here\n",
    "# WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx8zgVDGBujm"
   },
   "source": [
    "What do you see as $k$ increase?\n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfF6syENBujm"
   },
   "source": [
    "(d) Now copy the code above and let's see what happens when we go beyond $p=n$ (remember, in this case $k=p$). Test polynomial models up to $k=150$. Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree. \n",
    "\n",
    "Use the `geom_vline()` function in `ggplot` to draw a vertical line where $k=n$ (here $n$ is the number of observations in the training set). This will make it clear where we cross the threshold for finding *unique* solutions in our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fqk3xlUBBujm"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsiaI7CNBujn"
   },
   "source": [
    "What do you see as $k$ gets larger than $n$?\n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez8Cy8anBujn"
   },
   "source": [
    "---\n",
    "## 3. Applying regularization to the model fits (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFAAGungBujn"
   },
   "source": [
    "Repeat the previous bias-variance tradeoff test, going up to $k=150$, but now use ridge regression with a sparsity parameter of $\\lambda=0.00005$. Plot your results the same way as last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uVdEguGBujn"
   },
   "outputs": [],
   "source": [
    "# Now do the variance-bias trade off analysis using ridge regression\n",
    "lambda=0.00005\n",
    "degree = seq(2,150)\n",
    "\n",
    "rm(train_rss, test_rss)\n",
    "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "\n",
    "for (k in degree) {\n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "}\n",
    "\n",
    "# Plot your results here\n",
    "# WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IF6tO_uBujo"
   },
   "source": [
    "What happens now when $k$ gets larger than $n$?\n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zheO4rLBujo"
   },
   "source": [
    "---\n",
    "## 4. Reflection (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-65QvdnBujo"
   },
   "source": [
    "The simulations above should have shown that, when applying a regularization (i.e., a sparsity constraint), the behavior of the bias-variance tradeoff changes. Explain why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkM1H1_WBujo"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ietUafKfBujo"
   },
   "source": [
    "--- \n",
    "## Bonus (1 extra credit point)\n",
    "Recall that the $p=n$ threshold defines the limit for finding a *unique* solution to $Y=F(X)$ (i.e., there is only one combination of regression coefficients that is *best* at explaining variance in $Y$). With this in mind, what is regularization doing that works around this upper limit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo5eCrpuBujp"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmcAxEQCBujp"
   },
   "source": [
    "**DUE:** 5pm EST, April 12, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYdsoRobBujp"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> *Someone's Name*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
