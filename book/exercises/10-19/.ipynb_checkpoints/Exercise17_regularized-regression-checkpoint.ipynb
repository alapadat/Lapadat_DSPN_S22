{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0-Q9NYTBujb"
   },
   "source": [
    "# Exercise 17: Regularized regression\n",
    "\n",
    "This homework assignment is designed to give you an intuition as an interesting property of regularization in the context of ultra-high dimensional statistical problems.\n",
    "\n",
    "You won't need to load in any data for this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODln6rvBujd"
   },
   "source": [
    "---\n",
    "## 1. Simulating & visualizing data (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sezRLzgHBuje"
   },
   "source": [
    "We are going to be looking at what happens in the context where $p>n$. In order to have total control over our data, we will use simulations for this homework. First, we will need to load the `glmnet`, `tidyverse`, and `ggplot2` libraries for this assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LVJwea2rBujf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/roman/AppData/Local/R/win-library/4.2'\n",
      "(as 'lib' is unspecified)\n",
      "\n",
      "also installing the dependencies 'iterators', 'foreach', 'shape'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'iterators' successfully unpacked and MD5 sums checked\n",
      "package 'foreach' successfully unpacked and MD5 sums checked\n",
      "package 'shape' successfully unpacked and MD5 sums checked\n",
      "package 'glmnet' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\roman\\AppData\\Local\\Temp\\RtmpSQziPG\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'glmnet' was built under R version 4.2.3\"\n",
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.1-7\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.1     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.4     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 1.0.0\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mexpand()\u001b[39m masks \u001b[34mMatrix\u001b[39m::expand()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mpack()\u001b[39m   masks \u001b[34mMatrix\u001b[39m::pack()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32munpack()\u001b[39m masks \u001b[34mMatrix\u001b[39m::unpack()\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"glmnet\")\n",
    "library(glmnet)\n",
    "library(tidyverse)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXwMchX7Bujf"
   },
   "source": [
    "We are going to generate a data set with complex structure and try to recover it using polynomial models. For simplicity sake, use the following code to produce a response variable, $y$ that has complex structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpLho0wUde1L"
   },
   "source": [
    "*Hint: Look up what a cosine function looks like if you need a reminder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BeK03Sx7Bujg"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "set.seed(121)\n",
    "sigma_noise = .5\n",
    "x=seq(-9,9,by=.18)\n",
    "n=length(x)\n",
    "y = 0.1*x + cos(x) + cos(x/20)+rnorm(n,sd=sigma_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfmUWGIlBujg"
   },
   "source": [
    "(a) Break the data into a training set (n=50) and test set (n=51) using the `sample` function to randomly select subsets of x and y.  Make a separate data frame for the training and test data.\n",
    "\n",
    "(**Note**: *Do not* just take the first 50 observations to be the training set and last 51 observations to be the test set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "rIg6XGaHBujg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>sample.x..size...50..replace...FALSE.</th><th scope=col>sample.y..size...50..replace...FALSE.</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 5.40</td><td>-0.36612852</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 3.96</td><td>-0.08663415</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 3.42</td><td> 2.19168676</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-5.58</td><td> 1.39665096</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 0.90</td><td> 0.85446672</td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 1.26</td><td> 0.21482655</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & sample.x..size...50..replace...FALSE. & sample.y..size...50..replace...FALSE.\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  5.40 & -0.36612852\\\\\n",
       "\t2 &  3.96 & -0.08663415\\\\\n",
       "\t3 &  3.42 &  2.19168676\\\\\n",
       "\t4 & -5.58 &  1.39665096\\\\\n",
       "\t5 &  0.90 &  0.85446672\\\\\n",
       "\t6 &  1.26 &  0.21482655\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | sample.x..size...50..replace...FALSE. &lt;dbl&gt; | sample.y..size...50..replace...FALSE. &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 |  5.40 | -0.36612852 |\n",
       "| 2 |  3.96 | -0.08663415 |\n",
       "| 3 |  3.42 |  2.19168676 |\n",
       "| 4 | -5.58 |  1.39665096 |\n",
       "| 5 |  0.90 |  0.85446672 |\n",
       "| 6 |  1.26 |  0.21482655 |\n",
       "\n"
      ],
      "text/plain": [
       "  sample.x..size...50..replace...FALSE. sample.y..size...50..replace...FALSE.\n",
       "1  5.40                                 -0.36612852                          \n",
       "2  3.96                                 -0.08663415                          \n",
       "3  3.42                                  2.19168676                          \n",
       "4 -5.58                                  1.39665096                          \n",
       "5  0.90                                  0.85446672                          \n",
       "6  1.26                                  0.21482655                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>sample.x..size...51..replace...FALSE.</th><th scope=col>sample.y..size...51..replace...FALSE.</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-4.86</td><td>-0.3695457</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 6.48</td><td> 0.2132742</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 7.56</td><td> 0.9066007</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-8.10</td><td> 0.9080905</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-7.74</td><td> 0.7960581</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-8.46</td><td> 0.9704096</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & sample.x..size...51..replace...FALSE. & sample.y..size...51..replace...FALSE.\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & -4.86 & -0.3695457\\\\\n",
       "\t2 &  6.48 &  0.2132742\\\\\n",
       "\t3 &  7.56 &  0.9066007\\\\\n",
       "\t4 & -8.10 &  0.9080905\\\\\n",
       "\t5 & -7.74 &  0.7960581\\\\\n",
       "\t6 & -8.46 &  0.9704096\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | sample.x..size...51..replace...FALSE. &lt;dbl&gt; | sample.y..size...51..replace...FALSE. &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 | -4.86 | -0.3695457 |\n",
       "| 2 |  6.48 |  0.2132742 |\n",
       "| 3 |  7.56 |  0.9066007 |\n",
       "| 4 | -8.10 |  0.9080905 |\n",
       "| 5 | -7.74 |  0.7960581 |\n",
       "| 6 | -8.46 |  0.9704096 |\n",
       "\n"
      ],
      "text/plain": [
       "  sample.x..size...51..replace...FALSE. sample.y..size...51..replace...FALSE.\n",
       "1 -4.86                                 -0.3695457                           \n",
       "2  6.48                                  0.2132742                           \n",
       "3  7.56                                  0.9066007                           \n",
       "4 -8.10                                  0.9080905                           \n",
       "5 -7.74                                  0.7960581                           \n",
       "6 -8.46                                  0.9704096                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "#length(y)\n",
    "#typeof(y)\n",
    "\n",
    "trainy = data.frame(sample(y, size = 50, replace = FALSE))\n",
    "trainx = data.frame(sample(x, size = 50, replace = FALSE))\n",
    "train[\"x\"] = trainx \n",
    "train[\"y\"] = trainy\n",
    "train = data.frame(trainx,trainy)\n",
    "head(train)\n",
    "\n",
    "testy = data.frame(sample(y, size = 51, replace = FALSE))\n",
    "testx = data.frame(sample(x, size = 51, replace = FALSE))\n",
    "test[\"x\"] = testx\n",
    "test[\"y\"] = testy\n",
    "test = data.frame(testx, testy)\n",
    "head(test)\n",
    "\n",
    "#train\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ4B7a1lBujg"
   },
   "source": [
    "(b) Plot the training data ($x$ \\& $y$). Describe the relationship that you see in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "hRyRddZJBujh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nEiBASIAAIQEChAQI/ANwsOZYJSHFOgAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaVD7SEeBuji"
   },
   "source": [
    "How would you describe the relationship between $x$ and $y$ based on this plot?\n",
    "\n",
    "> *Weakly correlated, appears to be positive.*\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqLPa45zBuji"
   },
   "source": [
    "---\n",
    "## 2. Bias-variance tradeoff: polynomial regression (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyP55tOade1P"
   },
   "source": [
    "Recall that in polynomial regression we increase model complexity by expanding $x$ out to the power $k$ (which we call degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxra2iFvde1Q"
   },
   "source": [
    "\n",
    "$$Y = \\hat{\\beta}_0 + \\sum_{j=1}^K \\hat{\\beta}_jX^j $$  \n",
    "\n",
    "$$ = poly(x,k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SvSDGa9Buji"
   },
   "source": [
    "(a) Fit a 2nd degree polynomial regression model to the training data. Plot the results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vysWxHwVde1R"
   },
   "source": [
    "*Hint: Use the* `help` *function to see how to use the* `stat_smooth()` *and* `poly()` *functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_mZIsWwBuji"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYxz29TyBujj"
   },
   "source": [
    "How well does this 2nd degree polynomial model qualitatively fit the data? Could it do better? \n",
    "\n",
    "> *Write your response here*\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A83iJUkBujj"
   },
   "source": [
    "(b) Fit a 12th degree polynomial to the data. Does this do qualitatively better or worse than the 2nd degree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZAQ0PB5Bujj"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xanWSXvBujk"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpDFP-eSBujl"
   },
   "source": [
    "(c) Modify the loop below to estimate the bias-variance tradeoff as model complexity (i.e., degree of the polynomial model, $k$) increases from 2 to 50. Use the training data to fit the model and test data to evaluate its predictive accuracy. \n",
    "\n",
    "Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2kXJb-5de1S"
   },
   "source": [
    "\n",
    "(**Note**: We are using median accuracies here because there are often 1 or 2 outlier values in the higher degree polynomial models that can throw off the accuracy estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnoZVv4OBujl"
   },
   "outputs": [],
   "source": [
    "# Now do the variance-bias trade off analysis using regular regression\n",
    "degree = seq(2,50)\n",
    "\n",
    "# Need to setup your output vectors\n",
    "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "\n",
    "for (k in degree) {\n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "}\n",
    "\n",
    "# Plot your results here\n",
    "# WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx8zgVDGBujm"
   },
   "source": [
    "What do you see as $k$ increase?\n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfF6syENBujm"
   },
   "source": [
    "(d) Now copy the code above and let's see what happens when we go beyond $p=n$ (remember, in this case $k=p$). Test polynomial models up to $k=150$. Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree. \n",
    "\n",
    "Use the `geom_vline()` function in `ggplot` to draw a vertical line where $k=n$ (here $n$ is the number of observations in the training set). This will make it clear where we cross the threshold for finding *unique* solutions in our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fqk3xlUBBujm"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsiaI7CNBujn"
   },
   "source": [
    "What do you see as $k$ gets larger than $n$?\n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez8Cy8anBujn"
   },
   "source": [
    "---\n",
    "## 3. Applying regularization to the model fits (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFAAGungBujn"
   },
   "source": [
    "Repeat the previous bias-variance tradeoff test, going up to $k=150$, but now use ridge regression with a sparsity parameter of $\\lambda=0.00005$. Plot your results the same way as last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uVdEguGBujn"
   },
   "outputs": [],
   "source": [
    "# Now do the variance-bias trade off analysis using ridge regression\n",
    "lambda=0.00005\n",
    "degree = seq(2,150)\n",
    "\n",
    "rm(train_rss, test_rss)\n",
    "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "\n",
    "for (k in degree) {\n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "}\n",
    "\n",
    "# Plot your results here\n",
    "# WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IF6tO_uBujo"
   },
   "source": [
    "What happens now when $k$ gets larger than $n$?\n",
    "\n",
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zheO4rLBujo"
   },
   "source": [
    "---\n",
    "## 4. Reflection (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-65QvdnBujo"
   },
   "source": [
    "The simulations above should have shown that, when applying a regularization (i.e., a sparsity constraint), the behavior of the bias-variance tradeoff changes. Explain why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkM1H1_WBujo"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ietUafKfBujo"
   },
   "source": [
    "--- \n",
    "## Bonus (1 extra credit point)\n",
    "Recall that the $p=n$ threshold defines the limit for finding a *unique* solution to $Y=F(X)$ (i.e., there is only one combination of regression coefficients that is *best* at explaining variance in $Y$). With this in mind, what is regularization doing that works around this upper limit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo5eCrpuBujp"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmcAxEQCBujp"
   },
   "source": [
    "**DUE:** 5pm EST, April 12, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYdsoRobBujp"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> *Someone's Name*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
